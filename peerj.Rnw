%% Submissions for peer-review must enable line-numbering 
%% using the lineno option in the \documentclass command.
%%
%% Preprints and camera-ready submissions do not need 
%% line numbers, and should have this option removed.
%%
%% Please note that the line numbering option requires
%% version 1.1 or newer of the wlpeerj.cls file.

\documentclass[fleqn,10pt,lineno]{wlpeerj} % for journal submissions
% \documentclass[fleqn,10pt]{wlpeerj} % for preprint submissions

\title{The quality of software teams: A global online survey of industrial best practices}

\author[1]{Gunnar Rye Bergersen}
\author[1]{Viktoria Stray}
\affil[1]{Department of Informatics, University of Oslo, Norway}

\keywords{Keyword1, Keyword2, Keyword3}

\begin{abstract}
\emph{Context}: The Joel test describes a set of practices that are claimed to indicate the quality of a software team. These are practices such as source control, build in one step, daily builds and hallway usability testing. 
\emph{Goal}: To investigate which practices are applied among IT professionals and to analyse whether the Joel test is a good tool to indicate team quality. 
\emph{Method}: We conducted a survey at a english-speaking programming forum; after removing non-working programmers, we obtained 1542 responses. Nevne hvilke analyser som er gjort.  
\emph{Results}: Significant and positive relations were found between all the investigated variables a Joel test result. Higher Joel test results were also associated with respondents working at major IT production hubs, but some differences were present.  
\emph{Conclusion}: Overall, our early findings suggest that the Joel test can be used by organizations to quickly gauge the quality software teams; possible improvements are suggested.  
\end{abstract}

\begin{document}

\flushbottom
\maketitle
\thispagestyle{empty}

\section*{Introduction}

Your introduction goes here! Some examples of commonly used commands and features are listed below, to help you get started. Lets multiply 14 times 14. And the answer given by R is {\tt \Sexpr{14*14}}

If you have a question, please use the help menu in the top right of the screen to get in touch. When your article or pre-print is complete, use the "Submit to PeerJ" button in the topbar to send your files to PeerJ.

% \subsection*{About PeerJ}

% PeerJ is an award-winning open access publisher covering the biological and medical sciences.  PeerJ provides authors with three publication venues: \textit{PeerJ} and \textit{PeerJ Computer Science} (peer-reviewed academic journals) and \textit{PeerJ PrePrints} (a 'pre-print server'). See https://peerj.com/about/publications/ for more information.

The PeerJ model allows an author to publish articles in their peer-reviewed journal via the purchase of a lifetime Publication Plan. Prices start from just \$99 (a one-off payment) which entitles an author to the lifetime ability to publish 1 article per year for free. Publication in PeerJ PrePrints is entirely free.

\section*{Some \LaTeX{} Examples}
\label{sec:examples}

Use section and subsection commands to organize your document. \LaTeX{} handles all the formatting and numbering automatically. Use ref and label commands for cross-references.

\subsection*{Figures and Tables}

Use the table and tabular commands for basic tables --- see Table~\ref{tab:widgets}, for example. You can upload a figure (JPEG, PNG or PDF) using the project menu. To include it in your document, use the includegraphics command as in the code for Figure~\ref{fig:view} below.

<<Load_and_modify, echo=FALSE>>=
#install.packages("qgraph", dep = TRUE)
#library("qgraph")
#library("polycor")
install.packages("RUnit", dep = TRUE)
library("RUnit")
install.packages("psych", dep = TRUE)
library("psych")

# read the file
d.raw <- read.csv("data-analysis.csv", 
                     header = TRUE, 
                     sep = ";", 
                     quote = "\"",
                     dec = ",", 
                     # skip = 1, # toggle to use second line as variable input
                     fill = TRUE, 
                     comment.char = "")
# cat(paste(shQuote(names(data.raw), # convenience function for printing all the variables 
#                   type="cmd"), collapse=", ")) 
kUseVars <- c(#"X", "X.1", "Q0", 
  "Q1.X", "Q1.Y", "Q2", "Q3", "Q4.1", "Q4.2", "Q4.3", "Q5.1", "Q6", "Q7.1", "Q7.2", "Q8.0", "Q8.1", "Q8.2", "Q8.3", "Q8.4", "Q8.5", "Q9.1", "Q9.2", "Q9.3", "Q9.4", "Q9.5", "Q9.6", "Q9.7", "Q9.8", "Q9.9", "Q9.10", "Q9.11", "Q9.12", "Q11")
kJoelItemNames <- c("SourceCtrl", "Build1Step", "DailyBuilds",  "BugDB", "FixBugsB4Code", "Schedule", "Spec", "QuietWork", "BestTools", "Testers","CodeInterview", "UsabilityTest")
kJoelItems <- c("Q9.1", "Q9.2", "Q9.3", "Q9.4", "Q9.5", "Q9.6", "Q9.7", "Q9.8", "Q9.9", "Q9.10", "Q9.11", "Q9.12")

# import and clean data
d <- d.raw[kUseVars] # use a subset of variables
d[kJoelItems] <- d[kJoelItems] - 1 #Decrease the Joel test values by 1, e.g., 0 = no and 1 = yes

###############################################################################
# MAKE NEW VARIABLES
###############################################################################

d$professionals <- d$Q4.1 > 0 # 

# gender is not used
d$Q3.gender <- factor(d$Q3, labels = c("M", "F"))
d$Q3.gender <- if(d$Q3==1) {"M"} else {if(d$Q3!=1) "F"}
d$JoelSum <- rowSums(d[kJoelItems]) # calculate sum of Joel variables

# calculate months of experience
# exp <- c(10:11, 31) # TODO what is this?
d$Q7.1 <- as.integer(d$Q7.1) # enforce to numeric
d$Q7.2 <- as.integer(d$Q7.2) # change months to numeric TODO(gunnar): why is this numeric to begin with?
d$experience <- ((d$Q7.1 * 12) + d$Q7.2)
for (i in 1:nrow(d)) { # if years is valid but month is NA use years
  if(is.integer(d[i, ]$Q7.1) && is.na(d[i, ]$Q7.2)) {
    d[i, ]$experience <- d[i, ]$Q7.1 * 12
  }  
}
for (i in 1:nrow(d)) { # if months is valid but years is NA, use months
  if(is.na(d[i, ]$Q7.1) && is.integer(d[i, ]$Q7.2)) {
    d[i, ]$experience <- d[i, ]$Q7.2
  }  
}

# make logartimtic versions of experience
d$Q7ln <- log(d$experience + 0.001)
d$Q7 <- d$experience
d$Q4.1ln <- log(d$Q4.1 + 1)

# drop developers with unreasonably high experience
d <- d[d$experience < 720, ] # drops observations
checkEquals(dim(d)[[1]], 2500) # RUnit test

# calculate the actual hours spent coding per week
d$actualProgHours <- d$Q4.1 * (d$Q5.1/100)

# endcode US/West
d$USWest   <- ((d$Q1.X >= 128) & (d$Q1.X < 164) & (d$Q1.Y >= 197) & (d$Q1.Y < 259))
d$USEast   <- ((d$Q1.X >= 260) & (d$Q1.X < 290) & (d$Q1.Y >= 210) & (d$Q1.Y < 250))
d$London   <- ((d$Q1.X >= 480) & (d$Q1.X < 500) & (d$Q1.Y >= 170) & (d$Q1.Y < 190))
d$WorldRest <- (!d$USWest & !d$USEast & !d$London)

# encode intelligence, obsessed, and inept
d$Q11.intelligent <- (d$Q11==2 | d$Q11==6 | d$Q11==7 | d$Q11==4)
d$Q11.inept <-       (d$Q11==1 | d$Q11==4 | d$Q11==7 | d$Q11==5)
d$Q11.obsessed <-    (d$Q11==3 | d$Q11==6 | d$Q11==7 | d$Q11==5)

# Encode Q8 "software developement is talent versus fame"
kCareerItems <- c("Q8.0","Q8.1","Q8.2","Q8.3","Q8.4","Q8.5")
kCareerItemNames <- c("Scientist","Author","Musician","Athlete","Actor","Made sextape")
d[kCareerItems] <- d[kCareerItems] - 1
d$Q8 <- (d$Q8.0*6 + d$Q8.1*5 + d$Q8.2*4 + d$Q8.3*3 + d$Q8.4*2 + d$Q8.5*1) / 
  (d$Q8.0 + d$Q8.1 + d$Q8.2 + d$Q8.3 + d$Q8.4 + d$Q8.5)
d$Q8[is.nan(d$Q8)] <- NA # previous line results in some NaN, remove these
@

<<Figure1, echo=FALSE, out.width = '0.98\\textwidth', out.height = "0.43\\textheight">>=
###############################################################################
# PLOT THE WORLD
###############################################################################

library("ggplot2")
library("grid")
library("jpeg")

img <- readJPEG("theWorld5.jpg") # 1029 vs 609

# add some dummy points
d.plot <- d[,c("Q1.X", "Q1.Y")]
d.plot <- d.plot[!is.na(d.plot$Q1.X),]
d.plot <- d.plot[!is.na(d.plot$Q1.Y),]
d.plot = rbind(d.plot, c(0,0))
d.plot = rbind(d.plot, c(0,609))
d.plot = rbind(d.plot, c(1029,0))
d.plot = rbind(d.plot, c(1029,609))
dim(d.plot)

ggplot(d.plot, aes(Q1.X,-Q1.Y)) + 
  annotation_custom(rasterGrob(img, width=unit(1.0,"npc"), height=unit(1.0,"npc")), -Inf, Inf, -Inf, Inf) +
  stat_bin2d(bins=60, aes(fill=cut(..count.., c(1,5,20,50,100,Inf)))) +
  scale_fill_hue(h= c(275,020), l =75, c=60, na.value=rgb(0, 0, 0, alpha=0)) + 
  geom_point(color="black", alpha = 0.11) + 
  scale_x_continuous(expand=c(0,0)) +
  scale_y_continuous(expand=c(0,0)) +
  guides(fill=guide_legend(title=NULL)) +
  theme(legend.justification=c(.95,.75), legend.position=c(.95,.75)) + 
  theme(plot.margin=unit(c(0,0,0,0),"mm")) + #remove whitespace
#  scale_x_continuous(limit=c(0,1021)) +
#  scale_y_continuous(c(-629,0)) 
   geom_rect(xmin = 128, xmax = 163, ymin = -258, ymax = -197, color="black", fill=NA) + 
   geom_rect(xmin = 260, xmax = 289, ymin = -249, ymax = -210, color="black", fill=NA) +
   geom_rect(xmin = 480, xmax = 499, ymin = -189, ymax = -170, color="black", fill=NA)
@


\section*{Method}

To obtain responses from professionals, the users of a large, english-speaking programming related forum was asked to participate in a survey posted on Reddit. At the time, there were 345000 subscribers to the programming-related forum. Participation was thus voluntary and no compensation was offered except that the results would be posted at a later time. The survey open for four days. The majority of responses (85\%) came during the first 48 hours. 	

\subsection*{Respondents}

A total of \Sexpr{dim(d)[1]+2} individuals clicked on the link to the survey. 
The mean age of the respondents was \Sexpr{round(mean(d$Q2[d$professionals], na.rm=T),1)} years 
(\emph{n} = \Sexpr{sum(!is.na(d$Q2[d$professionals]))}, 
\emph{SD} = \Sexpr{round(sd(d$Q2[d$professionals], na.rm=T),1)} years, 
median = \Sexpr{(median(d$Q2[d$professionals], na.rm=T))} years). 
Only \Sexpr{(summary(d$Q3[d$professionals])[[4]]-1)*100}\% were female. 
The non-working respondents that were excluded from answering Joel's test were about one standard deviation younger 
(\emph{n} = \Sexpr{describe(d$Q2[!d$professionals],skew=F,range=T,check=T,trim=.1)[[2]]}, 
\emph{M} = \Sexpr{round(describe(d$Q2[!d$professionals],skew=F,range=T,check=T,trim=.1)$mean,1)} years, 
\emph{SD} = \Sexpr{round(describe(d$Q2[!d$professionals],skew=F,range=T,check=T,trim=.1)$sd,1)} years) that the analyzed repondents. 

\noindent{\tt Descriptives right out of R:}
<<Table1R, echo=FALSE>>=
###############################################################################
# DESCRIPTIVES
###############################################################################

# # Q3 - Gender
# sum(!is.na(d$Q3[d$professionals]))
# # females
# sum(!is.na(d$Q3[d$professionals & d$Q3==2])) / sum(!is.na(d$Q3[d$professionals]))

desc.vars <- c("Q2", "Q4.1", "Q4.2", "Q4.3", "Q5.1", "Q6", "actualProgHours", "experience")
desc.names <- c("Age", "Paid programming hrs", "Programming education hrs", "Unpaid (e.g., open source) hrs", "Fraction actual paid programming percent", "General programming skill 1-5 Likert scale", "Actual paid programming hrs week", "Programming experience yrs")

d.desc <- d[desc.vars]
d.desc$experience <- d.desc$experience/12
names(d.desc) <- desc.names

cols <- c(1,6:10)
# tab1 <- describe(d.desc[complete.cases(d$JoelSum),],skew=F,range=T,check=T,trim=.1) #Age all
tab1 <- describe(d.desc[d$professionals,],skew=F,range=T,check=T,trim=.1)
tab1 <- tab1[-cols]
@

<<Table1kable, echo=FALSE>>=
print("TABLE1: Descriptives for those who completed the Joel test");tab1
kable(tab1, format="latex", digits=c(0,2,2,2,2))
@

<<tab1xtable, results="asis", echo=FALSE>>=
library(xtable)
colnames(tab1) <- c("n", "mean", "SD", "median", "SE")
print(xtable(caption="Descriptives using xtable", tab1[-c(1),], digits=c(0,0,1,1,0,2), align=c("l", "|","r","r","r","r","r")), caption.placement = "top")
@



\begin{figure}[ht]
\centering
\includegraphics[width=\linewidth]{view.pdf}
\caption{An example image.}
\label{fig:view}
\end{figure}

\begin{table}[ht]
\centering
\begin{tabular}{l|c}
Item & Quantity \\\hline
Widgets & 42 \\
Gadgets & 13
\end{tabular}
\caption{\label{tab:widgets}An example table.}
\end{table}

\subsection*{Citations}

LaTeX formats citations and references automatically using the bibliography records in your .bib file, which you can edit via the project menu. Use the cite command for an inline citation, like \cite{Figueredo:2009dg}, and the citep command for a citation in parentheses \citep{Figueredo:2009dg}.


<<Table2, echo=FALSE>>=
###############################################################################
# TABLE 2: DESCRIPTIVES OF THE JOEL TEST using data frame
###############################################################################
library(gtools) # for making significance stars

getFishersP <- function(x1,x2,y1,y2) {
  tmp.matrix <- matrix(c(x1,x2,y1,y2), nrow=2)
  p <- fisher.test(tmp.matrix)$p.value
  return (p)
}

getFishersOR <- function(x1,x2,y1,y2) {
  tmp.matrix <- matrix(c(x1,x2,y1,y2), nrow=2)
  or <- fisher.test(tmp.matrix)$estimate
  return (or)
}

calculateFishersP <- function(q, d.h1, d.h0) { # q=question name
  x1 <- summary(d.h1[[q]])[[2]]
  x2 <- summary(d.h0[[q]])[[2]]
  y1 <- summary(d.h1[[q]])[[1]]
  y2 <- summary(d.h0[[q]])[[1]] 
  p <- getFishersP(x1,x2,y1,y2)
  return(p)
}

calculateFishersOR <- function(q, d.h1, d.h0) { # q=question name
  x1 <- summary(d.h1[[q]])[[2]]
  x2 <- summary(d.h0[[q]])[[2]]
  y1 <- summary(d.h1[[q]])[[1]]
  y2 <- summary(d.h0[[q]])[[1]] 
  or <- getFishersOR(x1,x2,y1,y2)
  return(or)
}

# Make variables
kORdigits <- 2
tab2 <- data.frame(name=kJoelItemNames)
nlist = list()

# work on a subset consisting of only professonals i.e, experience > 1
d.prof <- d[!is.na(d$professionals) & d$professionals==T,] # make n = 1542

# remove those who cannot be used due to missing location?
# rownames(d.prof[is.na(d.prof$Q1.X),])
# dim(d.prof[,])
# dim(d.prof[-c(528,1194,1473,1594,1659), ])
# d.prof <- d.prof[-c(528,1194,1473,1594,1659), ]

# ------ Make USWest
d.temp.h1 <- d.prof[d.prof$USWest,] # work on a subset for the USWest calculation
tab2 <- transform(tab2, nUSWest = describe(d.temp.h1[kJoelItems])$n) # get the n's
tab2 <- transform(tab2, USWest = 100*describe(d.temp.h1[kJoelItems])$mean) # get means
tab2 <- transform(tab2, USWest = round(tab2$USWest,1)) # round off decimals

# Make stars
d.temp.h1 <- lapply(d.temp.h1[ , kJoelItems], ordered) # make the joel data binary (must be done after sum function)
d.temp.h0 <- d.prof[d.prof$WorldRest,]
d.temp.h0 <- lapply(d.temp.h0[ , kJoelItems], ordered) # make the joel data binary (must be done after sum function)
for (i in 1:12) {
  tab2$USWestOR[[i]] <- round(calculateFishersOR(i, d.temp.h1, d.temp.h0), kORdigits)
  tab2$USWestsig[[i]] <- stars.pval(calculateFishersP(i, d.temp.h1, d.temp.h0))
}

# # Print
tab2$USWestsig <- gsub("\\s","",tab2$USWestsig) # remove whitespace
tab2$USWestsig <- gsub("\\.","+",tab2$USWestsig) # change . (p<0.10) to +
# tab2$USWest <- paste(format(tab2$USWest,digits=2,nsmall=1), tab2$USWestsig, sep="")
tab2$USWestOR <- paste(format(tab2$USWestOR,digits=2,nsmall=1), tab2$USWestsig, sep="")

# -------- END Make USWest

# ------ Make USEast
d.temp.h1 <- d.prof[d.prof$USEast,] # work on a subset for the USEast calculation
tab2 <- transform(tab2, nUSEast = describe(d.temp.h1[kJoelItems])$n) # get the n's
tab2 <- transform(tab2, USEast = 100*describe(d.temp.h1[kJoelItems])$mean) # get means
tab2 <- transform(tab2, USEast = round(tab2$USEast,1)) # round off to two decimals

# Make stars
d.temp.h1 <- lapply(d.temp.h1[ , kJoelItems], ordered) # make the joel data binary (must be done after sum function)
d.temp.h0 <- d.prof[d.prof$WorldRest,]
d.temp.h0 <- lapply(d.temp.h0[ , kJoelItems], ordered) # make the joel data binary (must be done after sum function)
for (i in 1:12) {
  tab2$USEastOR[[i]] <- round(calculateFishersOR(i, d.temp.h1, d.temp.h0), kORdigits)
  tab2$USEastsig[[i]] <- stars.pval(calculateFishersP(i, d.temp.h1, d.temp.h0))
}

# # Print
tab2$USEastsig <- gsub("\\s","",tab2$USEastsig) # remove whitespace
tab2$USEastsig <- gsub("\\.","+",tab2$USEastsig) # change . (p<0.10) to +
#tab2$USEast <- paste(format(tab2$USEast,digits=2,nsmall=1), tab2$USEastsig, sep="")
tab2$USEastOR <- paste(format(tab2$USEastOR,digits=2,nsmall=1), tab2$USEastsig, sep="")

# -------- END Make USEast

# ------ Make London
d.temp.h1 <- d.prof[d.prof$London,] # work on a subset for the London calculation
tab2 <- transform(tab2, nLondon = describe(d.temp.h1[kJoelItems])$n) # get the n's
tab2 <- transform(tab2, London = 100*describe(d.temp.h1[kJoelItems])$mean) # get means
tab2 <- transform(tab2, London = round(tab2$London,1)) # round off to two decimals

# Make stars
d.temp.h1 <- lapply(d.temp.h1[ , kJoelItems], ordered) # make the joel data binary (must be done after sum function)
d.temp.h0 <- d.prof[d.prof$WorldRest,]
d.temp.h0 <- lapply(d.temp.h0[ , kJoelItems], ordered) # make the joel data binary (must be done after sum function)
for (i in 1:12) {
  tab2$LondonOR[[i]] <- round(calculateFishersOR(i, d.temp.h1, d.temp.h0), kORdigits)
  tab2$Londonsig[[i]] <- stars.pval(calculateFishersP(i, d.temp.h1, d.temp.h0))
}

# # Print
tab2$Londonsig <- gsub("\\s","",tab2$Londonsig) # remove whitespace
tab2$Londonsig <- gsub("\\.","+",tab2$Londonsig) # change . (p<0.10) to +
#tab2$London <- paste(format(tab2$London,digits=2,nsmall=1), tab2$Londonsig, sep="")
tab2$LondonOR <- paste(format(tab2$LondonOR,digits=2,nsmall=1), tab2$Londonsig, sep="")
# -------- END Make London

# ------ Make WorldRest
d.temp.h1 <- d.prof[d.prof$WorldRest,] # work on a subset for the WorldRest calculation
tab2 <- transform(tab2, nWorldRest = describe(d.temp.h1[kJoelItems])$n) # get the n's
tab2 <- transform(tab2, WorldRest = 100*describe(d.temp.h1[kJoelItems])$mean) # get means
tab2 <- transform(tab2, WorldRest = round(tab2$WorldRest,1)) # round off to two decimals

# Make stars
d.temp.h1 <- lapply(d.temp.h1[ , kJoelItems], ordered) # make the joel data binary (must be done after sum function)
d.temp.h0 <- d.prof[!d.prof$WorldRest,]
d.temp.h0 <- lapply(d.temp.h0[ , kJoelItems], ordered) # make the joel data binary (must be done after sum function)
for (i in 1:12) {
  tab2$WorldRestOR[[i]] <- round(calculateFishersOR(i, d.temp.h1, d.temp.h0), kORdigits)
  tab2$WorldRestsig[[i]] <- stars.pval(calculateFishersP(i, d.temp.h1, d.temp.h0))
}

# # Print
tab2$WorldRestsig <- gsub("\\s","",tab2$WorldRestsig) # remove whitespace
tab2$WorldRestsig <- gsub("\\.","+",tab2$WorldRestsig) # change . (p<0.10) to +
#tab2$WorldRest <- paste(format(tab2$WorldRest,digits=2,nsmall=1), tab2$WorldRestsig, sep="")
tab2$WorldRestOR <- paste(format(tab2$WorldRestOR,digits=2,nsmall=1), tab2$WorldRestsig, sep="")
# -------- END Make WorldRest


# -------- total
d.temp.h1 <- d.prof[] # work on a subset for the WorldRest calculation
tab2 <- transform(tab2, nTotal = describe(d.temp.h1[kJoelItems])$n) # get the n's
tab2 <- transform(tab2, Total = 100*describe(d.temp.h1[kJoelItems])$mean) # get means
tab2 <- transform(tab2, Total = round(tab2$Total,1)) # round off to two decimals
for (i in 1:12) {
  tab2$TotalOR[[i]] <- ""
}
# -------- END total

#tab2 <- setNames(tab2, c("", "n", "\%"))
@

<<Table2print, results="asis", echo=FALSE>>=
italic <- function(x){
paste0('{\\emph{ ', x, '}}')
}
print(xtable(caption="Descriptives using xtable", tab2[,-c(6:17)], digits=c(0,0,0,0,0,0), align=c("l", "l", "r","r","r","r")), caption.placement = "top", sanitize.colnames.function = italic)
@

<<Table2decimalprint, results="asis", echo=FALSE>>=
require(xtable) 
#' Prints a LaTeX table with numeric columns aligned on their decimal points.
#' 
#' This function wraps the \code{\link{xtable}} and \code{\link{print.xtable}}
#' functions in the \code{xtable} package so that numeric columns are aligned
#' on their decimal place.
#' 
#' See \url{http://jason.bryer.org/posts/2013-01-04/xtable_with_aligned_decimals.html}
#' for more information.
#' 
#' @author Jason Bryer <jason@@bryer.org>
#' @param x a data frame to create a LaTeX table from.
#' @param cols a numeric vector indicating which columns should be aligned on
#'        decimal points. It defaults to all columns of type numeric.
#' @param colAlignment named character vector where each element name corresponds to a
#         column name and the value is the LaTeX alignment (i.e. l, r, or c).
#' @param tocharFun the function used to convert the numeric vecotr to a character
#'        vector. This defaults to \code{\link{prettyNum}}, but other possible
#'        options are \code{\link{as.character}}, \code{\link{format}}, 
#'        \code{\link{formatC}}, or some other custom function.
#' @param ... other parameters passed to \code{tocharFun}, \code{\link{xtable}},
#'        and \code{\link{print.xtable}}.
#' @seealso xtable
#' @export
xtable.decimal <- function(x, 
			cols=which(lapply(x, class) == 'numeric'), 
			colAlignment, 
			tocharFun=prettyNum,
			...) {
	splitCol <- function(x, ...) {
		s <- strsplit(tocharFun(x, ...), split='.', fixed=TRUE)
		right <- sapply(s, FUN=function(x) { ifelse(length(x) == 2, x[2], '0') })
		left <- sapply(s, FUN=function(x) { x[1] })
		data.frame(left=left, right=right, stringsAsFactors=FALSE)
	}

	cols <- cols[order(cols, decreasing=TRUE)]
	colnames <- names(x)
	for(i in cols) {
		if(i == 1) {
			tmp <- cbind(splitCol(x[,1], ...), x[,2:ncol(x)])
			names(tmp)[1:2] <- paste(names(tmp)[1], c('left','right'), sep='.')
			names(tmp)[3:ncol(x)] <- names(x)[2:ncol(x)]
			x <- tmp
		} else if(i == ncol(x)) {
			tmp <- cbind(x[,1:(ncol(x)-1)], splitCol(x[,ncol(x)], ...))
			names(tmp)[1:(ncol(tmp)-2)] <- names(x)[1:(ncol(x)-1)]
			names(tmp)[(ncol(tmp)-1):ncol(tmp)] <- paste(names(x)[ncol(x)], 
						c('left','right'), sep='.')
			x <- tmp
		} else {
			tmp <- cbind(x[,1:(i-1)], splitCol(x[,i], ...), x[,(i+1):ncol(x)])
			names(tmp)[1:(i-1)] <- names(x)[1:(i-1)]
			names(tmp)[i:(i+1)] <- paste(names(x)[i], c('left','right'), sep='.')
			names(tmp)[(i+2):ncol(tmp)] <- names(x)[(i+1):ncol(x)]
			x <- tmp
		}
	}

	colnames[cols] <- paste('\\multicolumn{2}{c}{', colnames[cols], '}', sep='')
	colnames <- paste(colnames, collapse=' & ')

	addtorow <- list()
	addtorow$pos <- list()
	addtorow$pos[[1]] <- c(0)
	addtorow$command <- paste( colnames, ' \\\\ ', sep='')

	align <- rep('l', ncol(x))
	if(!missing(colAlignment)) {
		for(i in seq_along(colAlignment)) {
			align[names(x) == names(colAlignment)[i]] <- colAlignment[i]
		}
	}
	align[grep('.left$', names(x), perl=TRUE)] <- 'r@{.}'
	align <- c('l', align) #Add an alignment for row names

	xtab <- xtable(x, align=align, ...)
	print(xtab, add.to.row=addtorow, include.rownames=FALSE, include.colnames=FALSE, ...)
}

require(xtable)
#tab2.temp <- tab2[,-c(2,6,10,14)] # remove n
#tab2.temp <- tab2
tab2.temp <- tab2[,-c(5,9,13,17)] # remove sig

# colnames(tab2.temp) <- c("", "%", "OR", "%", "OR", "%", "OR", "%", "OR")
tab2.temp.matrix <- as.matrix(tab2.temp)
# tab2.temp.matrix <- rbind(c("", "%", "OR", "", "%", "OR", "", "%", "OR", "", "%", "OR", ""), tab2.temp.matrix)
tab2.temp.matrix <- rbind(c("", 
#                            rep(c("n", "%", "OR", "sig"),4)),
                            rep(c("n", "%", "OR"),4), "n", "%", ""),
                          tab2.temp.matrix)
# tab2.temp.matrix <- setNames(tab2.temp.matrix,c("", "p", "OR", "p", "OR", "p", "OR", "p", "OR"))
rownames(tab2.temp.matrix) <- c('', 1:12)
xtable.val2 <- xtable(tab2.temp.matrix, align =c("l", "l", 
#                                                 rep(c("|", "r",  "r", "r", "l"), 4)))
                                                 rep(c("r",  "r", "l"), 5)))

# & \multicolumn{2}{c}{USWest}& \multicolumn{2}{c}{USEast}& \multicolumn{2}{c}{UK South}& \multicolumn{2}{c}{WorldRest}

addtorow <- list()
addtorow$pos <- list(0)
#addtorow$command <- paste0(paste0('& \\multicolumn{2}{c}{', sort(unique(sex)), '}', collapse=''), '\\\\')
addtorow$command <- paste0("& ", # fix first column element
                           paste0('& \\multicolumn{3}{c}{', c("USWest", "USEast", "UK South", "WorldRest", "Total"), '}', collapse=''), '\\\\')
 
print(xtable.val2, add.to.row=addtorow, include.colnames=F, scalebox=0.85, hline.after = c(-1,1,nrow(xtable.val2)))
@

\subsection*{Mathematics}

Now testing multicolumn in xtable

<<Table2multicolumnxtable, results="asis", echo=FALSE>>=
require(xtable)
age <- sample(c('30-50', '50-70', '70+'), 200, replace=T)
sex <- sample(c('Male', 'Female'), 200, replace=T)
val <- table(age, sex)
val <- rbind(val, formatC(prop.table(val)*100, format='f', digits=1))
val <- structure(val, dim=c(3, 4))
val <- rbind(c('n', '%'), val)
rownames(val) <- c('', sort(unique(age)))
val <- xtable(val)

addtorow <- list()
addtorow$pos <- list(0)
#addtorow$command <- paste0(paste0('& \\multicolumn{2}{c}{', sort(unique(sex)), '}', collapse=''), '\\\\')
addtorow$command <- paste0(paste0('& \\multicolumn{2}{c}{', c("Female", "MALE"), '}', collapse=''), '\\\\')

print(val, add.to.row=addtorow, include.colnames=F)
@


% latex table generated in R 3.3.0 by xtable 1.8-2 package## % Fri May 20 15:36:00 2016## 
\begin{table}[ht] 
\centering 
\begin{tabular}{lllllllll}   
\hline 
& \multicolumn{2}{c}{USWest}& \multicolumn{2}{c}{USEast}& \multicolumn{2}{c}{UK South}& \multicolumn{2}{c}{WorldRest}\\
& \% & OR & \% & OR & \% & OR & \% & OR\\ \hline
SourceCtrl & 97.2 & 2.1 & 94.2 & 1.0 & 96.6 & 1.7 & 94.3 & 0.7 \\   
Build1Step & 80.9 & 1.0 & 77.9 & 0.9 & 74.7 & 0.7 & 80.6 & 1.1 \\   
DailyBuilds & 68.4**& 1.7 & 57.1 & 1.0 & 65.5 & 1.5 & 56.3*& 0.7 \\   
BugDB & 77.0+ & 1.4 & 73.4 & 1.2 & 78.2 & 1.5 & 70.5*& 0.8 \\   
FixBugsB4Code & 52.8 & 1.0 & 51.9 & 1.0 & 54.0 & 1.0 & 53.1 & 1.0 \\   
Schedule & 60.7**& 1.7 & 50.3 & 1.1 & 54.0 & 1.3 & 48.2*& 0.7 \\   
Spec & 52.2*& 1.4 & 42.1 & 1.0 & 54.0+ & 1.6 & 43.1+ & 0.8 \\   
QuietWork & 66.7+ & 1.4 & 60.8 & 1.1 & 58.6 & 1.0 & 59.4 & 0.9 \\   
BestTools & 49.4**& 1.6 & 41.2 & 1.1 & 44.8 & 1.3 & 38.6*& 0.8 \\   
Testers & 57.1*& 1.4 & 54.6 & 1.3 & 55.2 & 1.3 & 48.3*& 0.7 \\   
CodeInterview & 65.5***& 2.6 & 52.6*& 1.5 & 62.4***& 2.3 & 42.2***& 0.5 \\   
UsabilityTest & 37.7**& 1.7 & 30.3 & 1.2 & 22.4 & 0.8 & 26.6+ & 0.8 \\    
\hline 
\end{tabular} 
\end{table}

% latex table generated in R 3.3.0 by xtable 1.8-2 package
% Fri May 20 13:52:41 2016
\begin{table}[ht]
\centering
\begin{tabular}{rllll}
  \hline
  & \multicolumn{2}{c}{Female}& \multicolumn{2}{c}{Male}\\
 & n & \% & n & \% \\ \hline
  30--50 & 29 & 14.5 & 46 & 23.0 \\ 
  50--70 & 33 & 16.5 & 29 & 14.5 \\ 
  70+ & 35 & 17.5 & 28 & 14.0 \\ 
   \hline
\end{tabular}
\end{table}

\LaTeX{} is great at typesetting mathematics. Let $X_1, X_2, \ldots, X_n$ be a sequence of independent and identically distributed random variables with $\text{E}[X_i] = \mu$ and $\text{Var}[X_i] = \sigma^2 < \infty$, and let
$$S_n = \frac{X_1 + X_2 + \cdots + X_n}{n}
      = \frac{1}{n}\sum_{i}^{n} X_i$$
denote their mean. Then as $n$ approaches infinity, the random variables $\sqrt{n}(S_n - \mu)$ converge in distribution to a normal $\mathcal{N}(0, \sigma^2)$.

\subsection*{Lists}

You can make lists with automatic numbering \dots

\begin{enumerate}[noitemsep] 
\item Like this,
\item and like this.
\end{enumerate}
\dots or bullet points \dots
\begin{itemize}[noitemsep] 
\item Like this,
\item and like this.
\end{itemize}
\dots or with words and descriptions \dots
\begin{description}
\item[Word] Definition
\item[Concept] Explanation
\item[Idea] Text
\end{description}

We hope you find write\LaTeX\ useful for your PeerJ submission, and please let us know if you have any feedback. Further examples with dummy text are included in the following pages.

\begin{equation}
\cos^3 \theta =\frac{1}{4}\cos\theta+\frac{3}{4}\cos 3\theta
\label{eq:refname2}
\end{equation}

\lipsum[5] % Dummy text

\subsection*{Subsection}

\lipsum[6] % Dummy text

\paragraph{Paragraph} \lipsum[7] % Dummy text
\paragraph{Paragraph} \lipsum[8] % Dummy text

\subsection*{Subsection}

\lipsum[9] % Dummy text

\begin{figure}[ht]\centering
\includegraphics[width=\linewidth]{results.pdf}
\caption{In-text Picture}
\label{fig:results}
\end{figure}

Reference to Figure \ref{fig:results}.

\section*{Results and Discussion}

\lipsum[10] % Dummy text

\subsection*{Subsection}

\lipsum[11] % Dummy text

\subsubsection*{Subsubsection}

\lipsum[12] % Dummy text

\subsubsection*{Subsubsection}

\lipsum[14] % Dummy text

\subsection*{Subsection}

\lipsum[15-20] % Dummy text

\section*{Acknowledgments}

So long and thanks for all the fish.

\bibliography{sample}

\end{document}